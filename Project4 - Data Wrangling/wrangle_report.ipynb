{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs - Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed the instructions given by Udacity team on how to gather data for this data wrangling analysis.\n",
    "\n",
    "   * Intially I downloaded the data which is a given CSV file and named as **twitter-archive-enhanced.csv**\n",
    "   * After that I created my twitter developer account and created the JSON file named **tweet_json.txt** by using the API.\n",
    "   * Then I downloaded the image predicitions file which is in tsv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting all the three files above, I created them into 3 different dataframes as shown in below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **archive_df** - This is a dataset \"twitter-archive-enhanced.csv\" which was converted into a dataframe and gives information on basic tweet data.\n",
    "* **tweet_info_df** - This dataset contains information such as tweet_id, no.of retweets and no.of faviorites etc.\n",
    "* **image_predictions_df**  - This dataset contains information about predictions about the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Assesing the Gathered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column of the table in twitter dataset is described in the cells below. To see the table columns that goes hand in hand with these descriptions, I displayed each table by displaying the pandas DataFrame that it was gathered into.This task is the mechincal part of visual assessment in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tweet_id**: The unique identifier  for each of the tweet.\n",
    "* **in_reply_to_status_id**: The status id for the reply given to the tweet id.\n",
    "* **in_reply_to_user_id**: The status of id for the reply given to the tweet id w.r.t user id.\n",
    "* **timestamp**: Date and time the tweet was created, in Excel-friendly format.\n",
    "* **source**: The web link as source.\n",
    "* **text**: The corresponding tweets text.\n",
    "* **retweeted_status_id**: The status id for the reply given to the tweer id i.e., for the retweet id\n",
    "* **retweeted_status_user_id**: The status id for the reply given to the tweer id(w.r.t user id) i.e., for the retweet id\n",
    "* **retweeted_status_timestamp**: Date and time the tweet was created, in Excel-friendly format.\n",
    "* **expanded_urls**: Expanded version of url1; URL entered by user and displayed in Twitter. Note that the user-entered URL\n",
    "    may itself be a shortened URL, e.g. from bit.ly.\n",
    "* **rating_numerator**: The ranking given by user.\n",
    "* **rating_denominator**: The reference ranking given by user.\n",
    "* **name**: The breed or dog's name.\n",
    "* **doggo, floofer, pupper, puppo** : The stage of the dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to the twitter columns: https://sfm.readthedocs.io/en/1.4.3/data_dictionary.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality - archive_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Missing values in columns from in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id,\n",
    "   retweeted_status_timestamp, expanded_urls.\n",
    "2. rating_numerator, rating_denominator have some inconsistent values in the numerator and denominator (some of them showing as    hish as 1776, 170 respectively.\n",
    "3. tweet id  8352464395298040 as a rating of denominator = 0\n",
    "4. Crazy names found for few dogs such as - 'infuriating', 'just', 'light', 'life', 'mad', 'my', 'not', 'officially',              'one','quite','old','space','such','the','this','unacceptable','very'.\n",
    "5. timestamp and retweeted_status_timestamp must be of datetime instead of the object.\n",
    "6. in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id must be integers instead of float      (Their id's are similar to tweet_id).\n",
    "7. The columns which have missing values in doggo, floofer, pupper, puppo - has **None** instead of 'NaN'.\n",
    "8. The information of text is truncated to 50 characters. Anything in excess is ellipsized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Tweets_info_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets_info_df columns and their description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tweet_id**: The unique identifier for each of the tweet.\n",
    "* **retweets**: The count of retweets done by user.\n",
    "* **Favorites**: The count of favorites done by each user\n",
    "* **followers**: The count of number of followers.\n",
    "* **friends**: The count of number of friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quality - tweets_info_df table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 23 tweet ids information is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Quality - image_predictions_df:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeRateDogs Twitter archive was ran through a neural network that can classify breeds of dogs. The results - a table full of \n",
    "image predictions(the top three only) alongside each tweetID, image  URL, and the image number that corresponded to the most\n",
    "confident prediction (numbered 1 to 4 since tweets can have up to four images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_predictions_df columns and their description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tweet_id**: tweet_id is the last part of the tweet URL after \"status/\".\n",
    "* **jpg_url**: Image link or URL.\n",
    "* **img_num**: Image number.\n",
    "* **p1**: p1 algorithm's #1 prediction for the image in the tweet.\n",
    "* **p1_conf**: p1_conf is how confident the algoritm is in its #1 prediction.\n",
    "* **p1_dog**: p1_dog is whether or not the #1 prediction is a breed of dog.\n",
    "* **p2**: is the algorithm's second most likely prediction.\n",
    "* **p2_conf**: is how confident the algoritm is in its #2 prediction.\n",
    "* **p2_dog**: p2_dog is whether or not the #2 prediction is a breed of dog.\n",
    "* **p3**: is the algorithm's third most likely prediction.\n",
    "* **p3_conf**: is how confident the algoritm is in its #3 prediction.\n",
    "* **p3_dog**: p3_dog is whether or not the #3 prediction is a breed of dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quality - image_predictions_df table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only 2075 tweetids have images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cleaning all the 3 dataframes, I followed the below steps before and after joining the dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert the datatype of 'tweet_id' into string.\n",
    "* Create a universe dataset joining all the dateframes based on the tweet_id.\n",
    "* Convert the dog stage or category into one columns instead of the multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing the above step, there are duplicated rows(332) becuase the count has increased from 2393 to 2061. These duplicated \n",
    "rows might have occured due to multiple tagging done with dog_status. Now lets clean the rows with only one dog_status column\n",
    "value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removed the kind of ambiguity between dog_stages.\n",
    "* in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id - convert all these into Object or   string.\n",
    "* retweeted_status_timestamp - Convert this variable into datetime format.\n",
    "* We see that the information of text is truncated to 50 characters. Anything in excess is ellipsized. Let us increase the text\n",
    "  format representation.\n",
    "* Crazy dog names found for few dogs such as - 'infuriating', 'just', 'light', 'life', 'mad', 'my', 'not', 'officially',         'one','quite','old','space','such','the','this','unacceptable','very'. Lets clean to ideal name by looking at the text.\n",
    "* rating_numerator and rating_denominator have some inconsistent values in the numerator and denominator is shown as 0. Hence,\n",
    "  assuming that the ratings are done purely on a humouros basis. Hence we are seeing the wide range of values. I am not going     to disturb the ratings provided here.\n",
    "* retweeted_status_timestamp - has the null values, dropped this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Storing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored the final dataframe into csv file with the name twitter_archive_master.csv with final data of 2048 rows and 30 columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
